# ChemLink Analytics Database

**Unified analytics database combining data from ChemLink Service and Engagement Platform for cross-database analytics and AI training data.**

---

## ğŸ¯ Purpose

This project creates a **local analytics database** that:
- Combines data from two production databases (read-only access)
- Provides unified views for cross-database analytics
- Pre-calculates aggregated metrics for performance
- Exports clean datasets for Alchemi AI training
- Enables cohort analysis and user journey tracking

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ engagement-platform â”‚    â”‚ chemlink-service    â”‚
â”‚ (Social Features)   â”‚    â”‚ (Profile/Finder)    â”‚
â”‚    PRODUCTION       â”‚    â”‚    PRODUCTION       â”‚
â”‚    READ-ONLY        â”‚    â”‚    READ-ONLY        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                          â”‚
           â”‚  ETL Pipeline (Python)   â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Analytics Database  â”‚
         â”‚     LOCALHOST        â”‚
         â”‚    PostgreSQL        â”‚
         â”‚                      â”‚
         â”‚  â€¢ staging/          â”‚
         â”‚  â€¢ core/             â”‚
         â”‚  â€¢ aggregates/       â”‚
         â”‚  â€¢ ai/               â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Database Schema

### Schema Organization

**`staging`** - Raw data copied from source databases  
**`core`** - Cleaned, transformed, and unified data  
**`aggregates`** - Materialized views for dashboards  
**`ai`** - Training datasets for machine learning

### Key Tables/Views

- `core.unified_users` - Master user table combining both DBs
- `aggregates.daily_metrics` - Pre-calculated daily KPIs
- `aggregates.cohort_retention` - Retention analysis
- `core.user_journey_events` - Lifecycle event tracking
- `ai.training_data_activation` - ML features for activation prediction
- `ai.training_data_engagement` - ML features for engagement prediction

---

## ğŸš€ Setup

### Prerequisites

- Python 3.8+
- PostgreSQL 14+ (installed locally)
- Access to ChemLink production databases (read-only credentials)

### Installation

1. **Create local analytics database**
   ```bash
   psql -U postgres
   CREATE DATABASE chemlink_analytics;
   \q
   ```

2. **Clone/navigate to project**
   ```bash
   cd ~/projects/chemlink-analytics-db
   ```

3. **Create virtual environment**
   ```bash
   python3 -m venv venv
   source venv/bin/activate
   ```

4. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

5. **Configure environment**
   ```bash
   cp .env.example .env
   # Edit .env with your local postgres credentials
   ```

6. **Initialize schema**
   ```bash
   python scripts/init_schema.py
   ```

7. **Run ETL pipeline**
   ```bash
   python scripts/etl_pipeline.py
   ```

---

## ğŸ“ Project Structure

```
chemlink-analytics-db/
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ .env                        # Configuration (not in git)
â”œâ”€â”€ .env.example                # Template for credentials
â”œâ”€â”€ db_config.py                # Database connection helpers
â”œâ”€â”€ schema/
â”‚   â”œâ”€â”€ 01_create_schemas.sql   # Schema definitions
â”‚   â”œâ”€â”€ 02_staging_tables.sql   # Staging layer tables
â”‚   â”œâ”€â”€ 03_core_tables.sql      # Core layer tables
â”‚   â”œâ”€â”€ 04_aggregate_views.sql  # Materialized views
â”‚   â””â”€â”€ 05_ai_views.sql         # AI training data views
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ init_schema.py          # Initialize database schema
â”‚   â”œâ”€â”€ etl_pipeline.py         # Main ETL orchestrator
â”‚   â”œâ”€â”€ extract.py              # Extract from source DBs
â”‚   â”œâ”€â”€ transform.py            # Transform and clean data
â”‚   â””â”€â”€ load.py                 # Load into analytics DB
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_connections.py     # Test DB connections
â”‚   â”œâ”€â”€ test_etl.py             # Test ETL pipeline
â”‚   â””â”€â”€ test_data_quality.py    # Validate data integrity
â””â”€â”€ docs/
    â”œâ”€â”€ ARCHITECTURE.md          # Technical design details
    â”œâ”€â”€ ETL_DESIGN.md           # ETL pipeline documentation
    â””â”€â”€ SCHEMA_DESIGN.md        # Database schema details
```

---

## ğŸ”„ ETL Pipeline

### Extract
Pulls data from production databases (read-only):
- `chemlink-service-prd`
- `engagement-platform-prd`

### Transform
- Joins data using `external_id` relationship
- Calculates derived metrics (profile_completion_score, engagement_score)
- Cleans data (removes test accounts, validates consistency)
- Handles soft deletes properly

### Load
- Inserts into staging schema
- Transforms into core schema
- Refreshes materialized views
- Exports AI training datasets

### Running the Pipeline

**Full refresh:**
```bash
python scripts/etl_pipeline.py --full
```

**Incremental update:**
```bash
python scripts/etl_pipeline.py --incremental
```

**Specific date range:**
```bash
python scripts/etl_pipeline.py --start-date 2025-10-01 --end-date 2025-10-31
```

---

## ğŸ”§ Configuration

### Environment Variables (`.env`)

```bash
# Source Database - ChemLink Service (Production, Read-Only)
CHEMLINK_PRD_DB_HOST=...
CHEMLINK_PRD_DB_PORT=5432
CHEMLINK_PRD_DB_NAME=chemlink-service-prd
CHEMLINK_PRD_DB_USER=chemlink-readonly
CHEMLINK_PRD_DB_PASSWORD=...

# Source Database - Engagement Platform (Production, Read-Only)
ENGAGEMENT_PRD_DB_HOST=...
ENGAGEMENT_PRD_DB_PORT=5432
ENGAGEMENT_PRD_DB_NAME=engagement-platform-prd
ENGAGEMENT_PRD_DB_USER=chemlink-readonly
ENGAGEMENT_PRD_DB_PASSWORD=...

# Analytics Database (Local)
ANALYTICS_DB_HOST=localhost
ANALYTICS_DB_PORT=5432
ANALYTICS_DB_NAME=chemlink_analytics
ANALYTICS_DB_USER=postgres
ANALYTICS_DB_PASSWORD=your_local_password

# ETL Configuration
ETL_BATCH_SIZE=1000
ETL_LOG_LEVEL=INFO
```

---

## ğŸ“Š Key Metrics Provided

### User Analytics
- New signups (daily/weekly/monthly)
- Growth rates
- User segmentation (Finder vs Standard)
- Profile completion rates

### Activity Analytics
- DAU/WAU/MAU (comprehensive, not just social)
- Activity by type (posts, comments, votes, collections, etc.)
- Engagement intensity levels
- Content type distribution

### Cohort Analytics
- Retention by signup cohort
- Activation rates
- Time-to-activation
- Churn analysis

### AI Training Data
- User activation prediction features
- Engagement level prediction features
- Behavioral pattern datasets
- Clean labeled data for ML models

---

## ğŸ¯ Success Criteria

### Phase 1: Foundation âœ…
- [x] Analytics DB created locally
- [ ] Schema designed and implemented
- [ ] ETL pipeline extracts from both source DBs
- [ ] Unified user view working

### Phase 2: Analytics
- [ ] Daily metrics aggregation running
- [ ] Cohort analysis tables populated
- [ ] User journey tracking implemented
- [ ] Dashboard queries 10x faster

### Phase 3: AI Readiness
- [ ] Clean training datasets exported
- [ ] Features engineered for ML models
- [ ] Historical data preserved properly
- [ ] Alchemi AI can consume data easily

---

## ğŸ”— Related Projects

**Source Project:** `chemlink-analytics-dashboard`
- Current Flask dashboard (direct DB queries)
- Reference for required metrics
- Context document: `ANALYTICS_DB_CONTEXT.md`

**Future Integration:**
Dashboard will eventually query this analytics DB instead of production databases directly.

---

## ğŸ“š Documentation

- `/docs/ARCHITECTURE.md` - Technical design and decisions
- `/docs/ETL_DESIGN.md` - ETL pipeline details
- `/docs/SCHEMA_DESIGN.md` - Database schema documentation
- `../chemlink-analytics-dashboard/ANALYTICS_DB_CONTEXT.md` - Full context handoff

---

## ğŸš¨ Important Notes

- **Production databases are READ-ONLY** - We never write to them
- **Local database only** - All transformations happen locally
- **No PII exposed** - Analytics data is aggregated and anonymized where needed
- **Incremental updates** - Pipeline supports both full and incremental refreshes

---

## ğŸ¤ Contributing

1. Always test ETL scripts on small datasets first
2. Document any new metrics or transformations
3. Keep schema migrations in separate SQL files
4. Update README when adding new features

---

## ğŸ“§ Support

Questions? Reference the context document:
`../chemlink-analytics-dashboard/ANALYTICS_DB_CONTEXT.md`
